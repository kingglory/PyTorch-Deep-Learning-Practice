{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d3b3ad",
   "metadata": {},
   "source": [
    "### 深度学习算法中，并没有过多的局部最优点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc4459c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.4\n",
      "epoch: 0 w= 1.1840000000000002 loss= 3.779999999999999\n",
      "epoch: 1 w= 1.2601600000000002 loss= 3.107327999999999\n",
      "epoch: 2 w= 1.3292117333333335 loss= 2.5543617194666655\n",
      "epoch: 3 w= 1.3918186382222224 loss= 2.0997988605891305\n",
      "epoch: 4 w= 1.4485822319881483 loss= 1.726127987798069\n",
      "epoch: 5 w= 1.5000478903359211 loss= 1.4189539227694705\n",
      "epoch: 6 w= 1.5467100872379018 loss= 1.1664431891352944\n",
      "epoch: 7 w= 1.5890171457623643 loss= 0.9588681433887288\n",
      "epoch: 8 w= 1.6273755454912102 loss= 0.7882322302274639\n",
      "epoch: 9 w= 1.6621538279120307 loss= 0.6479619257905413\n",
      "epoch: 10 w= 1.6936861373069079 loss= 0.5326535013076374\n",
      "epoch: 11 w= 1.722275431158263 loss= 0.4378648515638249\n",
      "epoch: 12 w= 1.7481963909168252 loss= 0.35994436864553353\n",
      "epoch: 13 w= 1.7716980610979216 loss= 0.2958902685541241\n",
      "epoch: 14 w= 1.7930062420621156 loss= 0.24323495143009244\n",
      "epoch: 15 w= 1.8123256594696515 loss= 0.19994994051782156\n",
      "epoch: 16 w= 1.829841931252484 loss= 0.16436773776967237\n",
      "epoch: 17 w= 1.8457233510022522 loss= 0.13511758567946033\n",
      "epoch: 18 w= 1.8601225049087087 loss= 0.11107266065454684\n",
      "epoch: 19 w= 1.8731777377838958 loss= 0.0913066636207332\n",
      "epoch: 20 w= 1.8850144822573989 loss= 0.07505813557018141\n",
      "epoch: 21 w= 1.895746463913375 loss= 0.061701123355825414\n",
      "epoch: 22 w= 1.9054767939481267 loss= 0.050721065670637756\n",
      "epoch: 23 w= 1.9142989598463016 loss= 0.041694970250849527\n",
      "epoch: 24 w= 1.9222977235939802 loss= 0.03427511865598718\n",
      "epoch: 25 w= 1.929549936058542 loss= 0.028175670873828263\n",
      "epoch: 26 w= 1.9361252753597447 loss= 0.023161653710325848\n",
      "epoch: 27 w= 1.9420869163261685 loss= 0.019039908756719372\n",
      "epoch: 28 w= 1.9474921374690595 loss= 0.015651651216190318\n",
      "epoch: 29 w= 1.9523928713052805 loss= 0.012866352928651383\n",
      "epoch: 30 w= 1.9568362033167876 loss= 0.010576713945259353\n",
      "epoch: 31 w= 1.9608648243405542 loss= 0.008694528939178551\n",
      "epoch: 32 w= 1.9645174407354358 loss= 0.007147289211513151\n",
      "epoch: 33 w= 1.9678291462667952 loss= 0.0058753893891621105\n",
      "epoch: 34 w= 1.9708317592818942 loss= 0.004829831206308542\n",
      "epoch: 35 w= 1.9735541284155842 loss= 0.003970335910750384\n",
      "epoch: 36 w= 1.976022409763463 loss= 0.0032637925780105745\n",
      "epoch: 37 w= 1.9782603181855398 loss= 0.0026829825565725693\n",
      "epoch: 38 w= 1.9802893551548895 loss= 0.002205530905171862\n",
      "epoch: 39 w= 1.9821290153404332 loss= 0.0018130444276470519\n",
      "epoch: 40 w= 1.9837969739086594 loss= 0.0014904030992782143\n",
      "epoch: 41 w= 1.9853092563438512 loss= 0.001225177587744435\n",
      "epoch: 42 w= 1.986680392418425 loss= 0.0010071504294631426\n",
      "epoch: 43 w= 1.9879235557927053 loss= 0.0008279224152600113\n",
      "epoch: 44 w= 1.9890506905853862 loss= 0.0006805890218955468\n",
      "epoch: 45 w= 1.9900726261307502 loss= 0.0005594744243990976\n",
      "epoch: 46 w= 1.9909991810252134 loss= 0.00045991284238603526\n",
      "epoch: 47 w= 1.9918392574628603 loss= 0.0003780687970120875\n",
      "epoch: 48 w= 1.9926009267663267 loss= 0.00031078935420158463\n",
      "epoch: 49 w= 1.993291506934803 loss= 0.0002554826620138884\n",
      "epoch: 50 w= 1.9939176329542214 loss= 0.00021001810296038273\n",
      "epoch: 51 w= 1.9944853205451607 loss= 0.00017264421477133918\n",
      "epoch: 52 w= 1.9950000239609458 loss= 0.00014192121761826272\n",
      "epoch: 53 w= 1.9954666883912575 loss= 0.00011666554849188071\n",
      "epoch: 54 w= 1.99588979747474 loss= 9.590426599580841e-05\n",
      "epoch: 55 w= 1.9962734163770977 loss= 7.883756906038572e-05\n",
      "epoch: 56 w= 1.9966212308485685 loss= 6.480798565959189e-05\n",
      "epoch: 57 w= 1.9969365826360355 loss= 5.3275044567102166e-05\n",
      "epoch: 58 w= 1.9972225015900056 loss= 4.3794454413916016e-05\n",
      "epoch: 59 w= 1.9974817347749383 loss= 3.600098794843496e-05\n",
      "epoch: 60 w= 1.9977167728626106 loss= 2.9594412137523848e-05\n",
      "epoch: 61 w= 1.9979298740621003 loss= 2.432792208425368e-05\n",
      "epoch: 62 w= 1.9981230858163044 loss= 1.99986331942359e-05\n",
      "epoch: 63 w= 1.9982982644734493 loss= 1.643976531380474e-05\n",
      "epoch: 64 w= 1.998457093122594 loss= 1.3514217744183569e-05\n",
      "epoch: 65 w= 1.9986010977644852 loss= 1.1109287617618656e-05\n",
      "epoch: 66 w= 1.9987316619731332 loss= 9.132328167798157e-06\n",
      "epoch: 67 w= 1.9988500401889742 loss= 7.5071796351832156e-06\n",
      "epoch: 68 w= 1.9989573697713365 loss= 6.17123531254751e-06\n",
      "epoch: 69 w= 1.9990546819260118 loss= 5.073029704038952e-06\n",
      "epoch: 70 w= 1.9991429116129174 loss= 4.170255884707836e-06\n",
      "epoch: 71 w= 1.999222906529045 loss= 3.42813568193609e-06\n",
      "epoch: 72 w= 1.9992954352530008 loss= 2.8180798921378555e-06\n",
      "epoch: 73 w= 1.9993611946293874 loss= 2.31658691933224e-06\n",
      "epoch: 74 w= 1.999420816463978 loss= 1.9043374071097219e-06\n",
      "epoch: 75 w= 1.9994748735940067 loss= 1.5654499858619878e-06\n",
      "epoch: 76 w= 1.9995238853918993 loss= 1.2868694639340347e-06\n",
      "epoch: 77 w= 1.999568322755322 loss= 1.0578638935521584e-06\n",
      "epoch: 78 w= 1.999608612631492 loss= 8.696111366728735e-07\n",
      "epoch: 79 w= 1.9996451421192194 loss= 7.14859003729107e-07\n",
      "epoch: 80 w= 1.9996782621880922 loss= 5.876458725766218e-07\n",
      "epoch: 81 w= 1.9997082910505368 loss= 4.830710248522341e-07\n",
      "epoch: 82 w= 1.9997355172191533 loss= 3.9710585225211706e-07\n",
      "epoch: 83 w= 1.999760202278699 loss= 3.264386597003717e-07\n",
      "epoch: 84 w= 1.9997825833993539 loss= 2.683470866583658e-07\n",
      "epoch: 85 w= 1.9998028756154143 loss= 2.2059323177019588e-07\n",
      "epoch: 86 w= 1.9998212738913088 loss= 1.8133744065859905e-07\n",
      "epoch: 87 w= 1.9998379549947867 loss= 1.4906743566342276e-07\n",
      "epoch: 88 w= 1.9998530791952733 loss= 1.2254005733474364e-07\n",
      "epoch: 89 w= 1.9998667918037145 loss= 1.0073337335381603e-07\n",
      "epoch: 90 w= 1.9998792245687012 loss= 8.280730993573403e-08\n",
      "epoch: 91 w= 1.999890496942289 loss= 6.807128909202579e-08\n",
      "epoch: 92 w= 1.9999007172276755 loss= 5.595762502418181e-08\n",
      "epoch: 93 w= 1.9999099836197591 loss= 4.599965477543858e-08\n",
      "epoch: 94 w= 1.9999183851485816 loss= 3.7813760654370585e-08\n",
      "epoch: 95 w= 1.9999260025347139 loss= 3.108459186958808e-08\n",
      "epoch: 96 w= 1.9999329089648072 loss= 2.5552916054305896e-08\n",
      "epoch: 97 w= 1.9999391707947585 loss= 2.100563268170711e-08\n",
      "epoch: 98 w= 1.9999448481872477 loss= 1.7267563648115425e-08\n",
      "epoch: 99 w= 1.9999499956897713 loss= 1.4194704766028049e-08\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# prepare the training set\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    " \n",
    "# initial guess of weight \n",
    "w = 1.1\n",
    " \n",
    "# define the model linear model y = w*x\n",
    "def forward(x):\n",
    "    return x*w\n",
    " \n",
    "#define the cost function MSE \n",
    "def cost(xs, ys):\n",
    "    cost = 0\n",
    "    for x, y in zip(xs,ys):\n",
    "        y_pred = forward(x)\n",
    "        cost += (y_pred - y)**2\n",
    "    return cost / len(xs)\n",
    " \n",
    "# define the gradient function  gd\n",
    "def gradient(xs,ys):\n",
    "    grad = 0\n",
    "    for x, y in zip(xs,ys):\n",
    "        grad += 2*x*(x*w - y)\n",
    "    return grad / len(xs)\n",
    " \n",
    "epoch_list = []\n",
    "cost_list = []\n",
    "print('predict (before training)', 4, forward(4))\n",
    "for epoch in range(100):\n",
    "    cost_val = cost(x_data, y_data)\n",
    "    grad_val = gradient(x_data, y_data)\n",
    "    w-= 0.01 * grad_val  # 0.01 learning rate\n",
    "    print('epoch:', epoch, 'w=', w, 'loss=', cost_val)\n",
    "    epoch_list.append(epoch)\n",
    "    cost_list.append(cost_val)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59ae988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (after training) 4 7.999799982759085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('predict (after training)', 4, forward(4))\n",
    "plt.plot(epoch_list,cost_list)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epoch')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bf1e3b6",
   "metadata": {},
   "source": [
    "随机梯度下降法和梯度下降法的主要区别在于：\n",
    "\n",
    "1、损失函数由cost()更改为loss()。cost是计算所有训练数据的损失，loss是计算一个训练函数的损失。对应于源代码则是少了两个for循环。\n",
    "\n",
    "2、梯度函数gradient()由计算所有训练数据的梯度均值更改为计算一个训练数据的梯度。\n",
    "\n",
    "3、本算法中的随机梯度主要是指，每次拿一个训练数据来训练，然后更新梯度参数。本算法中梯度总共更新100(epoch)x3 = 300次。梯度下降法中梯度总共更新100(epoch)次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfdda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.4\n",
      "\tgrad: 1.0 2.0 -1.7999999999999998\n",
      "\tgrad: 2.0 4.0 -7.055999999999999\n",
      "\tgrad: 3.0 6.0 -14.605919999999998\n",
      "progress: 0 w= 1.3346192000000001 loss= 3.98458448107776\n",
      "\tgrad: 1.0 2.0 -1.3307615999999998\n",
      "\tgrad: 2.0 4.0 -5.2165854719999984\n",
      "\tgrad: 3.0 6.0 -10.79833192704\n",
      "progress: 1 w= 1.5080759899904002 loss= 2.177903084615325\n",
      "\tgrad: 1.0 2.0 -0.9838480200191997\n",
      "\tgrad: 2.0 4.0 -3.856684238475262\n",
      "\tgrad: 3.0 6.0 -7.983336373643791\n",
      "progress: 2 w= 1.6363146763117828 loss= 1.1904031319958301\n",
      "\tgrad: 1.0 2.0 -0.7273706473764343\n",
      "\tgrad: 2.0 4.0 -2.8512929377156233\n",
      "\tgrad: 3.0 6.0 -5.902176381071341\n",
      "progress: 3 w= 1.7311230759734166 loss= 0.650653202465973\n",
      "\tgrad: 1.0 2.0 -0.5377538480531667\n",
      "\tgrad: 2.0 4.0 -2.1079950843684134\n",
      "\tgrad: 3.0 6.0 -4.363549824642618\n",
      "progress: 4 w= 1.8012160635440586 loss= 0.35563548053627825\n",
      "\tgrad: 1.0 2.0 -0.3975678729118828\n",
      "\tgrad: 2.0 4.0 -1.5584660618145811\n",
      "\tgrad: 3.0 6.0 -3.2260247479561848\n",
      "progress: 5 w= 1.853036650370885 loss= 0.19438403520788572\n",
      "\tgrad: 1.0 2.0 -0.2939266992582299\n",
      "\tgrad: 2.0 4.0 -1.1521926610922613\n",
      "\tgrad: 3.0 6.0 -2.3850388084609833\n",
      "progress: 6 w= 1.8913482320589998 loss= 0.10624686009034487\n",
      "\tgrad: 1.0 2.0 -0.21730353588200035\n",
      "\tgrad: 2.0 4.0 -0.8518298606574408\n",
      "\tgrad: 3.0 6.0 -1.7632878115609003\n",
      "progress: 7 w= 1.9196724441400033 loss= 0.05807264607396806\n",
      "\tgrad: 1.0 2.0 -0.16065511171999347\n",
      "\tgrad: 2.0 4.0 -0.6297680379423749\n",
      "\tgrad: 3.0 6.0 -1.3036198385407172\n",
      "progress: 8 w= 1.940612874022034 loss= 0.03174147658730515\n",
      "\tgrad: 1.0 2.0 -0.11877425195593183\n",
      "\tgrad: 2.0 4.0 -0.46559506766725356\n",
      "\tgrad: 3.0 6.0 -0.9637817900712129\n",
      "progress: 9 w= 1.956094385118978 loss= 0.017349327162725494\n",
      "\tgrad: 1.0 2.0 -0.08781122976204392\n",
      "\tgrad: 2.0 4.0 -0.3442200206672119\n",
      "\tgrad: 3.0 6.0 -0.7125354427811281\n",
      "progress: 10 w= 1.967540052051082 loss= 0.009482833987618263\n",
      "\tgrad: 1.0 2.0 -0.06491989589783609\n",
      "\tgrad: 2.0 4.0 -0.25448599191951793\n",
      "\tgrad: 3.0 6.0 -0.5267860032733989\n",
      "progress: 11 w= 1.9760019709619896 loss= 0.005183148579382779\n",
      "\tgrad: 1.0 2.0 -0.04799605807602081\n",
      "\tgrad: 2.0 4.0 -0.18814454765800193\n",
      "\tgrad: 3.0 6.0 -0.38945921365206004\n",
      "progress: 12 w= 1.9822579691558504 loss= 0.002833016926272803\n",
      "\tgrad: 1.0 2.0 -0.03548406168829921\n",
      "\tgrad: 2.0 4.0 -0.13909752181813317\n",
      "\tgrad: 3.0 6.0 -0.2879318701635345\n",
      "progress: 13 w= 1.98688310369255 loss= 0.0015484767186635631\n",
      "\tgrad: 1.0 2.0 -0.026233792614899887\n",
      "\tgrad: 2.0 4.0 -0.10283646705040717\n",
      "\tgrad: 3.0 6.0 -0.2128714867943433\n",
      "progress: 14 w= 1.9903025211571466 loss= 0.0008463698631683101\n",
      "\tgrad: 1.0 2.0 -0.01939495768570687\n",
      "\tgrad: 2.0 4.0 -0.07602823412797122\n",
      "\tgrad: 3.0 6.0 -0.1573784446449018\n",
      "progress: 15 w= 1.9928305375217323 loss= 0.00046261073004560065\n",
      "\tgrad: 1.0 2.0 -0.014338924956535326\n",
      "\tgrad: 2.0 4.0 -0.056208585829619295\n",
      "\tgrad: 3.0 6.0 -0.11635177266731311\n",
      "progress: 16 w= 1.994699530356267 loss= 0.00025285480599723163\n",
      "\tgrad: 1.0 2.0 -0.010600939287466193\n",
      "\tgrad: 2.0 4.0 -0.041555682006867656\n",
      "\tgrad: 3.0 6.0 -0.08602026175421429\n",
      "progress: 17 w= 1.9960812991867525 loss= 0.00013820594457371067\n",
      "\tgrad: 1.0 2.0 -0.007837401626495044\n",
      "\tgrad: 2.0 4.0 -0.030722614375861212\n",
      "\tgrad: 3.0 6.0 -0.06359581175803442\n",
      "progress: 18 w= 1.9971028574643563 loss= 7.554091384652197e-05\n",
      "\tgrad: 1.0 2.0 -0.0057942850712873195\n",
      "\tgrad: 2.0 4.0 -0.02271359747944679\n",
      "\tgrad: 3.0 6.0 -0.04701714678245139\n",
      "progress: 19 w= 1.9978581077576882 loss= 4.128932139907485e-05\n",
      "\tgrad: 1.0 2.0 -0.004283784484623521\n",
      "\tgrad: 2.0 4.0 -0.016792435179723952\n",
      "\tgrad: 3.0 6.0 -0.0347603408220305\n",
      "progress: 20 w= 1.998416473362552 loss= 2.2568009503561683e-05\n",
      "\tgrad: 1.0 2.0 -0.00316705327489597\n",
      "\tgrad: 2.0 4.0 -0.012414848837591919\n",
      "\tgrad: 3.0 6.0 -0.025698737093815538\n",
      "progress: 21 w= 1.998829279754615 loss= 1.2335273036587358e-05\n",
      "\tgrad: 1.0 2.0 -0.002341440490770008\n",
      "\tgrad: 2.0 4.0 -0.009178446723819178\n",
      "\tgrad: 3.0 6.0 -0.018999384718309642\n",
      "progress: 22 w= 1.9991344724739437 loss= 6.742241085252351e-06\n",
      "\tgrad: 1.0 2.0 -0.0017310550521125734\n",
      "\tgrad: 2.0 4.0 -0.006785735804280435\n",
      "\tgrad: 3.0 6.0 -0.014046473114861513\n",
      "progress: 23 w= 1.9993601051136565 loss= 3.6851891901182257e-06\n",
      "\tgrad: 1.0 2.0 -0.0012797897726870566\n",
      "\tgrad: 2.0 4.0 -0.005016775908933013\n",
      "\tgrad: 3.0 6.0 -0.010384726131487554\n",
      "progress: 24 w= 1.9995269180317876 loss= 2.0142589378299707e-06\n",
      "\tgrad: 1.0 2.0 -0.0009461639364247709\n",
      "\tgrad: 2.0 4.0 -0.0037089626307853507\n",
      "\tgrad: 3.0 6.0 -0.0076775526457257826\n",
      "progress: 25 w= 1.9996502448239168 loss= 1.100958148772164e-06\n",
      "\tgrad: 1.0 2.0 -0.0006995103521663104\n",
      "\tgrad: 2.0 4.0 -0.0027420805804911907\n",
      "\tgrad: 3.0 6.0 -0.005676106801617564\n",
      "progress: 26 w= 1.9997414218012597 loss= 6.017641637743998e-07\n",
      "\tgrad: 1.0 2.0 -0.0005171563974806226\n",
      "\tgrad: 2.0 4.0 -0.002027253078123792\n",
      "\tgrad: 3.0 6.0 -0.004196413871715876\n",
      "progress: 27 w= 1.999808830034733 loss= 3.289136005820112e-07\n",
      "\tgrad: 1.0 2.0 -0.000382339930534048\n",
      "\tgrad: 2.0 4.0 -0.0014987725276931485\n",
      "\tgrad: 3.0 6.0 -0.003102459132328761\n",
      "progress: 28 w= 1.9998586657506385 loss= 1.797783303829405e-07\n",
      "\tgrad: 1.0 2.0 -0.00028266849872293776\n",
      "\tgrad: 2.0 4.0 -0.0011080605149942357\n",
      "\tgrad: 3.0 6.0 -0.002293685266039347\n",
      "progress: 29 w= 1.999895509893436 loss= 9.826364132827779e-08\n",
      "\tgrad: 1.0 2.0 -0.00020898021312820703\n",
      "\tgrad: 2.0 4.0 -0.0008192024354620742\n",
      "\tgrad: 3.0 6.0 -0.0016957490414046816\n",
      "progress: 30 w= 1.999922749210336 loss= 5.370916053354812e-08\n",
      "\tgrad: 1.0 2.0 -0.00015450157932805908\n",
      "\tgrad: 2.0 4.0 -0.000605646190965814\n",
      "\tgrad: 3.0 6.0 -0.001253687615299981\n",
      "progress: 31 w= 1.999942887564192 loss= 2.935647291520048e-08\n",
      "\tgrad: 1.0 2.0 -0.00011422487161594219\n",
      "\tgrad: 2.0 4.0 -0.0004477614967353105\n",
      "\tgrad: 3.0 6.0 -0.0009268662982453435\n",
      "progress: 32 w= 1.9999577760908578 loss= 1.6045726529193124e-08\n",
      "\tgrad: 1.0 2.0 -8.444781828442771e-05\n",
      "\tgrad: 2.0 4.0 -0.00033103544767421056\n",
      "\tgrad: 3.0 6.0 -0.0006852433766866284\n",
      "progress: 33 w= 1.9999687833572843 loss= 8.770309041850804e-09\n",
      "\tgrad: 1.0 2.0 -6.24332854313181e-05\n",
      "\tgrad: 2.0 4.0 -0.000244738478890838\n",
      "\tgrad: 3.0 6.0 -0.0005066086513068058\n",
      "progress: 34 w= 1.9999769211614404 loss= 4.793695103356855e-09\n",
      "\tgrad: 1.0 2.0 -4.615767711912966e-05\n",
      "\tgrad: 2.0 4.0 -0.0001809380943065264\n",
      "\tgrad: 3.0 6.0 -0.00037454185521568206\n",
      "progress: 35 w= 1.999982937537707 loss= 2.6201485755382967e-09\n",
      "\tgrad: 1.0 2.0 -3.4124924586098615e-05\n",
      "\tgrad: 2.0 4.0 -0.0001337697043766184\n",
      "\tgrad: 3.0 6.0 -0.0002769032880589606\n",
      "progress: 36 w= 1.9999873855168773 loss= 1.432126660066043e-09\n",
      "\tgrad: 1.0 2.0 -2.5228966245460782e-05\n",
      "\tgrad: 2.0 4.0 -9.889754768188652e-05\n",
      "\tgrad: 3.0 6.0 -0.00020471792370102548\n",
      "progress: 37 w= 1.9999906739612536 loss= 7.82774988276922e-10\n",
      "\tgrad: 1.0 2.0 -1.8652077492742336e-05\n",
      "\tgrad: 2.0 4.0 -7.311614377236708e-05\n",
      "\tgrad: 3.0 6.0 -0.0001513504176120506\n",
      "progress: 38 w= 1.9999931051476423 loss= 4.278509013219336e-10\n",
      "\tgrad: 1.0 2.0 -1.3789704715438944e-05\n",
      "\tgrad: 2.0 4.0 -5.4055642484840405e-05\n",
      "\tgrad: 3.0 6.0 -0.00011189517994303344\n",
      "progress: 39 w= 1.9999949025529138 loss= 2.338557011568929e-10\n",
      "\tgrad: 1.0 2.0 -1.0194894172421698e-05\n",
      "\tgrad: 2.0 4.0 -3.9963985155822e-05\n",
      "\tgrad: 3.0 6.0 -8.272544926946068e-05\n",
      "progress: 40 w= 1.9999962313961999 loss= 1.2782137141156108e-10\n",
      "\tgrad: 1.0 2.0 -7.537207600272211e-06\n",
      "\tgrad: 2.0 4.0 -2.954585379377761e-05\n",
      "\tgrad: 3.0 6.0 -6.11599173545585e-05\n",
      "progress: 41 w= 1.9999972138259872 loss= 6.986489066082714e-11\n",
      "\tgrad: 1.0 2.0 -5.5723480256730795e-06\n",
      "\tgrad: 2.0 4.0 -2.1843604260496363e-05\n",
      "\tgrad: 3.0 6.0 -4.5216260820879484e-05\n",
      "progress: 42 w= 1.9999979401481183 loss= 3.818690796927473e-11\n",
      "\tgrad: 1.0 2.0 -4.119703763461047e-06\n",
      "\tgrad: 2.0 4.0 -1.6149238753371264e-05\n",
      "\tgrad: 3.0 6.0 -3.3428924220757494e-05\n",
      "progress: 43 w= 1.9999984771267856 loss= 2.0872285446843958e-11\n",
      "\tgrad: 1.0 2.0 -3.0457464288424774e-06\n",
      "\tgrad: 2.0 4.0 -1.1939326000742767e-05\n",
      "\tgrad: 3.0 6.0 -2.4714404821324365e-05\n",
      "progress: 44 w= 1.999998874121558 loss= 1.1408420396092578e-11\n",
      "\tgrad: 1.0 2.0 -2.2517568840640934e-06\n",
      "\tgrad: 2.0 4.0 -8.826886984891757e-06\n",
      "\tgrad: 3.0 6.0 -1.8271656060164787e-05\n",
      "progress: 45 w= 1.9999991676245572 loss= 6.2356398976826376e-12\n",
      "\tgrad: 1.0 2.0 -1.664750885588262e-06\n",
      "\tgrad: 2.0 4.0 -6.525823470937553e-06\n",
      "\tgrad: 3.0 6.0 -1.3508454584254537e-05\n",
      "progress: 46 w= 1.9999993846148467 loss= 3.4082899810743715e-12\n",
      "\tgrad: 1.0 2.0 -1.2307703065594922e-06\n",
      "\tgrad: 2.0 4.0 -4.824619601606628e-06\n",
      "\tgrad: 3.0 6.0 -9.986962574259906e-06\n",
      "progress: 47 w= 1.9999995450383714 loss= 1.8629107520353415e-12\n",
      "\tgrad: 1.0 2.0 -9.09923257186307e-07\n",
      "\tgrad: 2.0 4.0 -3.566899168916393e-06\n",
      "\tgrad: 3.0 6.0 -7.383481277045689e-06\n",
      "progress: 48 w= 1.9999996636414084 loss= 1.0182339195670069e-12\n",
      "\tgrad: 1.0 2.0 -6.727171832920931e-07\n",
      "\tgrad: 2.0 4.0 -2.637051357723408e-06\n",
      "\tgrad: 3.0 6.0 -5.4586963109670705e-06\n",
      "progress: 49 w= 1.999999751326057 loss= 5.56548569644446e-13\n",
      "\tgrad: 1.0 2.0 -4.973478859859881e-07\n",
      "\tgrad: 2.0 4.0 -1.9496037122479493e-06\n",
      "\tgrad: 3.0 6.0 -4.035679683767057e-06\n",
      "progress: 50 w= 1.99999981615237 loss= 3.041995590483785e-13\n",
      "\tgrad: 1.0 2.0 -3.676952600173422e-07\n",
      "\tgrad: 2.0 4.0 -1.44136541990747e-06\n",
      "\tgrad: 3.0 6.0 -2.983626417929486e-06\n",
      "progress: 51 w= 1.999999864079241 loss= 1.6627007477004498e-13\n",
      "\tgrad: 1.0 2.0 -2.7184151818460123e-07\n",
      "\tgrad: 2.0 4.0 -1.065618750573094e-06\n",
      "\tgrad: 3.0 6.0 -2.205830814006049e-06\n",
      "progress: 52 w= 1.9999998995121517 loss= 9.088026883975772e-14\n",
      "\tgrad: 1.0 2.0 -2.0097569652932634e-07\n",
      "\tgrad: 2.0 4.0 -7.878247298975793e-07\n",
      "\tgrad: 3.0 6.0 -1.6307971879570005e-06\n",
      "progress: 53 w= 1.999999925708128 loss= 4.9673540091817305e-14\n",
      "\tgrad: 1.0 2.0 -1.485837439751947e-07\n",
      "\tgrad: 2.0 4.0 -5.824482762761818e-07\n",
      "\tgrad: 3.0 6.0 -1.2056679334904175e-06\n",
      "progress: 54 w= 1.9999999450751276 loss= 2.7150674427889273e-14\n",
      "\tgrad: 1.0 2.0 -1.098497448559499e-07\n",
      "\tgrad: 2.0 4.0 -4.3061099930241653e-07\n",
      "\tgrad: 3.0 6.0 -8.913647686625836e-07\n",
      "progress: 55 w= 1.9999999593933826 loss= 1.484007633732407e-14\n",
      "\tgrad: 1.0 2.0 -8.121323480381193e-08\n",
      "\tgrad: 2.0 4.0 -3.1835588032436135e-07\n",
      "\tgrad: 3.0 6.0 -6.58996675895196e-07\n",
      "progress: 56 w= 1.9999999699790405 loss= 8.1113220016135e-15\n",
      "\tgrad: 1.0 2.0 -6.004191899222633e-08\n",
      "\tgrad: 2.0 4.0 -2.3536432181003875e-07\n",
      "\tgrad: 3.0 6.0 -4.872041436954078e-07\n",
      "progress: 57 w= 1.9999999778051445 loss= 4.433504470030143e-15\n",
      "\tgrad: 1.0 2.0 -4.438971101805578e-08\n",
      "\tgrad: 2.0 4.0 -1.740076669420887e-07\n",
      "\tgrad: 3.0 6.0 -3.601958677990069e-07\n",
      "progress: 58 w= 1.9999999835910771 loss= 2.4232747309789728e-15\n",
      "\tgrad: 1.0 2.0 -3.2817845774246734e-08\n",
      "\tgrad: 2.0 4.0 -1.286459561100628e-07\n",
      "\tgrad: 3.0 6.0 -2.662971283484694e-07\n",
      "progress: 59 w= 1.9999999878686863 loss= 1.3245189556348814e-15\n",
      "\tgrad: 1.0 2.0 -2.4262627462690034e-08\n",
      "\tgrad: 2.0 4.0 -9.51094989432022e-08\n",
      "\tgrad: 3.0 6.0 -1.968766643045683e-07\n",
      "progress: 60 w= 1.9999999910311743 loss= 7.23958507048213e-16\n",
      "\tgrad: 1.0 2.0 -1.793765136426373e-08\n",
      "\tgrad: 2.0 4.0 -7.031559334791382e-08\n",
      "\tgrad: 3.0 6.0 -1.455532760985534e-07\n",
      "progress: 61 w= 1.9999999933692396 loss= 3.9570286724213515e-16\n",
      "\tgrad: 1.0 2.0 -1.3261520770413426e-08\n",
      "\tgrad: 2.0 4.0 -5.1985161064749263e-08\n",
      "\tgrad: 3.0 6.0 -1.0760928148556559e-07\n",
      "progress: 62 w= 1.9999999950977994 loss= 2.1628414704247495e-16\n",
      "\tgrad: 1.0 2.0 -9.80440129083604e-09\n",
      "\tgrad: 2.0 4.0 -3.843325302455014e-08\n",
      "\tgrad: 3.0 6.0 -7.955683045679507e-08\n",
      "progress: 63 w= 1.9999999963757442 loss= 1.1821707474356371e-16\n",
      "\tgrad: 1.0 2.0 -7.2485115687470625e-09\n",
      "\tgrad: 2.0 4.0 -2.8414165242907075e-08\n",
      "\tgrad: 3.0 6.0 -5.881732434431797e-08\n",
      "progress: 64 w= 1.9999999973205442 loss= 6.461534893200214e-17\n",
      "\tgrad: 1.0 2.0 -5.358911536745836e-09\n",
      "\tgrad: 2.0 4.0 -2.100693308193513e-08\n",
      "\tgrad: 3.0 6.0 -4.348435211909418e-08\n",
      "progress: 65 w= 1.9999999980190462 loss= 3.531760059943054e-17\n",
      "\tgrad: 1.0 2.0 -3.961907690808175e-09\n",
      "\tgrad: 2.0 4.0 -1.5530678965092193e-08\n",
      "\tgrad: 3.0 6.0 -3.2148502526752054e-08\n",
      "progress: 66 w= 1.999999998535457 loss= 1.93039720293512e-17\n",
      "\tgrad: 1.0 2.0 -2.9290858627462057e-09\n",
      "\tgrad: 2.0 4.0 -1.1482017114872178e-08\n",
      "\tgrad: 3.0 6.0 -2.376777707979727e-08\n",
      "progress: 67 w= 1.999999998917246 loss= 1.0551206694585956e-17\n",
      "\tgrad: 1.0 2.0 -2.1655082171889717e-09\n",
      "\tgrad: 2.0 4.0 -8.488791891636538e-09\n",
      "\tgrad: 3.0 6.0 -1.757180001504821e-08\n",
      "progress: 68 w= 1.999999999199507 loss= 5.7671014625865975e-18\n",
      "\tgrad: 1.0 2.0 -1.6009860104304607e-09\n",
      "\tgrad: 2.0 4.0 -6.275865160887406e-09\n",
      "\tgrad: 3.0 6.0 -1.299103757901321e-08\n",
      "progress: 69 w= 1.9999999994081858 loss= 3.152194350857071e-18\n",
      "\tgrad: 1.0 2.0 -1.1836283064781128e-09\n",
      "\tgrad: 2.0 4.0 -4.639822748231381e-09\n",
      "\tgrad: 3.0 6.0 -9.604434580978705e-09\n",
      "progress: 70 w= 1.9999999995624647 loss= 1.722934573908438e-18\n",
      "\tgrad: 1.0 2.0 -8.750706825821908e-10\n",
      "\tgrad: 2.0 4.0 -3.4302765072879993e-09\n",
      "\tgrad: 3.0 6.0 -7.100672050341927e-09\n",
      "progress: 71 w= 1.999999999676525 loss= 9.417256854444517e-19\n",
      "\tgrad: 1.0 2.0 -6.469500490879909e-10\n",
      "\tgrad: 2.0 4.0 -2.536044263479198e-09\n",
      "\tgrad: 3.0 6.0 -5.249614076774378e-09\n",
      "progress: 72 w= 1.999999999760851 loss= 5.147295472518402e-19\n",
      "\tgrad: 1.0 2.0 -4.782978457740228e-10\n",
      "\tgrad: 2.0 4.0 -1.8749268804185704e-09\n",
      "\tgrad: 3.0 6.0 -3.881098109559389e-09\n",
      "progress: 73 w= 1.9999999998231943 loss= 2.8134176905827957e-19\n",
      "\tgrad: 1.0 2.0 -3.5361136241363056e-10\n",
      "\tgrad: 2.0 4.0 -1.3861569669870732e-09\n",
      "\tgrad: 3.0 6.0 -2.869342097255867e-09\n",
      "progress: 74 w= 1.9999999998692854 loss= 1.5377629463584345e-19\n",
      "\tgrad: 1.0 2.0 -2.6142910058979396e-10\n",
      "\tgrad: 2.0 4.0 -1.0248015769320773e-09\n",
      "\tgrad: 3.0 6.0 -2.121337772109655e-09\n",
      "progress: 75 w= 1.9999999999033613 loss= 8.405108240142597e-20\n",
      "\tgrad: 1.0 2.0 -1.9327739408936395e-10\n",
      "\tgrad: 2.0 4.0 -7.57648166427316e-10\n",
      "\tgrad: 3.0 6.0 -1.5683347953654447e-09\n",
      "progress: 76 w= 1.9999999999285538 loss= 4.594110787745053e-20\n",
      "\tgrad: 1.0 2.0 -1.428923646074054e-10\n",
      "\tgrad: 2.0 4.0 -5.60138602168081e-10\n",
      "\tgrad: 3.0 6.0 -1.159488505209083e-09\n",
      "progress: 77 w= 1.999999999947179 loss= 2.5110669604281343e-20\n",
      "\tgrad: 1.0 2.0 -1.0564216168518215e-10\n",
      "\tgrad: 2.0 4.0 -4.141167408988622e-10\n",
      "\tgrad: 3.0 6.0 -8.572236254167365e-10\n",
      "progress: 78 w= 1.9999999999609488 loss= 1.3724918684902267e-20\n",
      "\tgrad: 1.0 2.0 -7.810241342554036e-11\n",
      "\tgrad: 2.0 4.0 -3.0616220669799077e-10\n",
      "\tgrad: 3.0 6.0 -6.337543823065062e-10\n",
      "progress: 79 w= 1.9999999999711289 loss= 7.501878137625503e-21\n",
      "\tgrad: 1.0 2.0 -5.774225542154454e-11\n",
      "\tgrad: 2.0 4.0 -2.2635049390373752e-10\n",
      "\tgrad: 3.0 6.0 -4.685425381012465e-10\n",
      "progress: 80 w= 1.999999999978655 loss= 4.1004811641821095e-21\n",
      "\tgrad: 1.0 2.0 -4.268985165367667e-11\n",
      "\tgrad: 2.0 4.0 -1.6734347241254e-10\n",
      "\tgrad: 3.0 6.0 -3.4640024182408524e-10\n",
      "progress: 81 w= 1.9999999999842193 loss= 2.241235245333757e-21\n",
      "\tgrad: 1.0 2.0 -3.156142014404395e-11\n",
      "\tgrad: 2.0 4.0 -1.2372147750738804e-10\n",
      "\tgrad: 3.0 6.0 -2.561044709636917e-10\n",
      "progress: 82 w= 1.999999999988333 loss= 1.2250312891583942e-21\n",
      "\tgrad: 1.0 2.0 -2.333377935315184e-11\n",
      "\tgrad: 2.0 4.0 -9.14681663743977e-11\n",
      "\tgrad: 3.0 6.0 -1.893418755116727e-10\n",
      "progress: 83 w= 1.9999999999913745 loss= 6.695772130326628e-22\n",
      "\tgrad: 1.0 2.0 -1.7251089445835532e-11\n",
      "\tgrad: 2.0 4.0 -6.762412851912813e-11\n",
      "\tgrad: 3.0 6.0 -1.3997869530157914e-10\n",
      "progress: 84 w= 1.999999999993623 loss= 3.659750730339052e-22\n",
      "\tgrad: 1.0 2.0 -1.2753798017683948e-11\n",
      "\tgrad: 2.0 4.0 -4.999556324492005e-11\n",
      "\tgrad: 3.0 6.0 -1.0349054946345859e-10\n",
      "progress: 85 w= 1.9999999999952855 loss= 2.0003443847567008e-22\n",
      "\tgrad: 1.0 2.0 -9.42890210353653e-12\n",
      "\tgrad: 2.0 4.0 -3.696065675740101e-11\n",
      "\tgrad: 3.0 6.0 -7.650413635928999e-11\n",
      "progress: 86 w= 1.9999999999965146 loss= 1.0933890535376676e-22\n",
      "\tgrad: 1.0 2.0 -6.970868327016433e-12\n",
      "\tgrad: 2.0 4.0 -2.7325697260494053e-11\n",
      "\tgrad: 3.0 6.0 -5.6562754480182775e-11\n",
      "progress: 87 w= 1.9999999999974232 loss= 5.976379925695625e-23\n",
      "\tgrad: 1.0 2.0 -5.153655280309977e-12\n",
      "\tgrad: 2.0 4.0 -2.020250633449905e-11\n",
      "\tgrad: 3.0 6.0 -4.1817216356321296e-11\n",
      "progress: 88 w= 1.9999999999980949 loss= 3.266611871800055e-23\n",
      "\tgrad: 1.0 2.0 -3.810285420513537e-12\n",
      "\tgrad: 2.0 4.0 -1.4935608305677306e-11\n",
      "\tgrad: 3.0 6.0 -3.091393807608256e-11\n",
      "progress: 89 w= 1.9999999999985916 loss= 1.7851172078430632e-23\n",
      "\tgrad: 1.0 2.0 -2.816857858078947e-12\n",
      "\tgrad: 2.0 4.0 -1.1041834113711957e-11\n",
      "\tgrad: 3.0 6.0 -2.2856383452563023e-11\n",
      "progress: 90 w= 1.9999999999989586 loss= 9.763198153948534e-24\n",
      "\tgrad: 1.0 2.0 -2.0827783941967937e-12\n",
      "\tgrad: 2.0 4.0 -8.164136033883551e-12\n",
      "\tgrad: 3.0 6.0 -1.6898482613214583e-11\n",
      "progress: 91 w= 1.9999999999992302 loss= 5.33269971929404e-24\n",
      "\tgrad: 1.0 2.0 -1.539657290550167e-12\n",
      "\tgrad: 2.0 4.0 -6.036060540282051e-12\n",
      "\tgrad: 3.0 6.0 -1.2491341294662561e-11\n",
      "progress: 92 w= 1.999999999999431 loss= 2.914118448202456e-24\n",
      "\tgrad: 1.0 2.0 -1.1382006448457105e-12\n",
      "\tgrad: 2.0 4.0 -4.462208380573429e-12\n",
      "\tgrad: 3.0 6.0 -9.235279208041902e-12\n",
      "progress: 93 w= 1.9999999999995792 loss= 1.5929002831193811e-24\n",
      "\tgrad: 1.0 2.0 -8.415490526658687e-13\n",
      "\tgrad: 2.0 4.0 -3.298694650766265e-12\n",
      "\tgrad: 3.0 6.0 -6.8265393338151625e-12\n",
      "progress: 94 w= 1.999999999999689 loss= 8.713765447680349e-25\n",
      "\tgrad: 1.0 2.0 -6.221689829999377e-13\n",
      "\tgrad: 2.0 4.0 -2.438937940496544e-12\n",
      "\tgrad: 3.0 6.0 -5.0466297807361116e-12\n",
      "progress: 95 w= 1.99999999999977 loss= 4.762582054481762e-25\n",
      "\tgrad: 1.0 2.0 -4.600764214046649e-13\n",
      "\tgrad: 2.0 4.0 -1.8030021919912542e-12\n",
      "\tgrad: 3.0 6.0 -3.730349362740526e-12\n",
      "progress: 96 w= 1.99999999999983 loss= 2.599107356085981e-25\n",
      "\tgrad: 1.0 2.0 -3.4017233474514796e-13\n",
      "\tgrad: 2.0 4.0 -1.334043986389588e-12\n",
      "\tgrad: 3.0 6.0 -2.7604585284279892e-12\n",
      "progress: 97 w= 1.999999999999874 loss= 1.4248800100554526e-25\n",
      "\tgrad: 1.0 2.0 -2.517985819849855e-13\n",
      "\tgrad: 2.0 4.0 -9.876544027065393e-13\n",
      "\tgrad: 3.0 6.0 -2.0463630789890885e-12\n",
      "progress: 98 w= 1.9999999999999067 loss= 7.82747233205549e-26\n",
      "\tgrad: 1.0 2.0 -1.865174681370263e-13\n",
      "\tgrad: 2.0 4.0 -7.318590178329032e-13\n",
      "\tgrad: 3.0 6.0 -1.5134560271690134e-12\n",
      "progress: 99 w= 1.999999999999931 loss= 4.282646968354351e-26\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    " \n",
    "w = 1.1\n",
    " \n",
    "def forward(x):\n",
    "    return x*w\n",
    " \n",
    "# calculate loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)**2\n",
    " \n",
    "# define the gradient function  sgd\n",
    "def gradient(x, y):\n",
    "    return 2*x*(x*w - y)\n",
    " \n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "print('predict (before training)', 4, forward(4))\n",
    "for epoch in range(100):\n",
    "    for x,y in zip(x_data, y_data):\n",
    "        grad = gradient(x,y)\n",
    "        w = w - 0.01*grad    # update weight by every grad of sample of training set\n",
    "        print(\"\\tgrad:\", x, y,grad)\n",
    "        l = loss(x,y)\n",
    "    print(\"progress:\",epoch,\"w=\",w,\"loss=\",l)\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(l)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaa7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (after training) 4 7.999999999999724\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('predict (after training)', 4, forward(4))\n",
    "plt.plot(epoch_list,loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c437dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
