{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5d3ac9",
   "metadata": {},
   "source": [
    "说明：   \n",
    "    1、乘的权重(w)都一样，加的偏置(b)也一样。b变成矩阵时使用广播机制。神经网络的参数w和b是网络需要学习的，其他是已知的。   \n",
    "    2、学习能力越强，有可能会把输入样本中噪声的规律也学到。我们要学习数据本身真实数据的规律，学习能力要有泛化能力。   \n",
    "    3、该神经网络共3层；第一层是8维到6维的非线性空间变换，第二层是6维到4维的非线性空间变换，第三层是4维到1维的非线性空间变换。   \n",
    "    4、本算法中torch.nn.Sigmoid() # 将其看作是网络的一层，而不是简单的函数使用    \n",
    "    5、torch.sigmoid、torch.nn.Sigmoid和torch.nn.functional.sigmoid的区别:https://blog.csdn.net/yyhaohaoxuexi/article/details/90411791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a385157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6683276295661926\n",
      "1 0.6662523150444031\n",
      "2 0.6644324660301208\n",
      "3 0.6627258658409119\n",
      "4 0.6611259579658508\n",
      "5 0.6596853733062744\n",
      "6 0.6583685278892517\n",
      "7 0.6571210026741028\n",
      "8 0.655944287776947\n",
      "9 0.6548483967781067\n",
      "10 0.6538336277008057\n",
      "11 0.652886688709259\n",
      "12 0.6519993543624878\n",
      "13 0.651175856590271\n",
      "14 0.6504220366477966\n",
      "15 0.6497375965118408\n",
      "16 0.6491182446479797\n",
      "17 0.6485562920570374\n",
      "18 0.648044764995575\n",
      "19 0.6475796103477478\n",
      "20 0.6471604108810425\n",
      "21 0.6467875838279724\n",
      "22 0.6464560627937317\n",
      "23 0.6461595892906189\n",
      "24 0.6459039449691772\n",
      "25 0.6456974148750305\n",
      "26 0.6455320715904236\n",
      "27 0.6453973054885864\n",
      "28 0.645284116268158\n",
      "29 0.6451845765113831\n",
      "30 0.645094096660614\n",
      "31 0.6450113654136658\n",
      "32 0.6449353694915771\n",
      "33 0.6448622345924377\n",
      "34 0.6447862982749939\n",
      "35 0.6447044014930725\n",
      "36 0.6446159482002258\n",
      "37 0.6445207595825195\n",
      "38 0.6444282531738281\n",
      "39 0.6443448066711426\n",
      "40 0.6442784667015076\n",
      "41 0.6442432999610901\n",
      "42 0.6441525220870972\n",
      "43 0.6440226435661316\n",
      "44 0.6438956260681152\n",
      "45 0.643790066242218\n",
      "46 0.6436938047409058\n",
      "47 0.6435920596122742\n",
      "48 0.6434739232063293\n",
      "49 0.6433399319648743\n",
      "50 0.6431986689567566\n",
      "51 0.6430597901344299\n",
      "52 0.6429266333580017\n",
      "53 0.6427991986274719\n",
      "54 0.6426651477813721\n",
      "55 0.6425169706344604\n",
      "56 0.6423659920692444\n",
      "57 0.642220139503479\n",
      "58 0.6420758366584778\n",
      "59 0.641930878162384\n",
      "60 0.6417819857597351\n",
      "61 0.6416254639625549\n",
      "62 0.6414650678634644\n",
      "63 0.6413076519966125\n",
      "64 0.6411503553390503\n",
      "65 0.6409843564033508\n",
      "66 0.6408094167709351\n",
      "67 0.6406335234642029\n",
      "68 0.6404571533203125\n",
      "69 0.640272319316864\n",
      "70 0.6400762796401978\n",
      "71 0.6398753523826599\n",
      "72 0.6396715641021729\n",
      "73 0.6394583582878113\n",
      "74 0.6392356157302856\n",
      "75 0.639009416103363\n",
      "76 0.6387782692909241\n",
      "77 0.6385388970375061\n",
      "78 0.6382913589477539\n",
      "79 0.6380300521850586\n",
      "80 0.6377412676811218\n",
      "81 0.637425422668457\n",
      "82 0.6371014714241028\n",
      "83 0.6367562413215637\n",
      "84 0.6363898515701294\n",
      "85 0.6360053420066833\n",
      "86 0.6355830430984497\n",
      "87 0.6351205706596375\n",
      "88 0.6346701979637146\n",
      "89 0.6342592835426331\n",
      "90 0.6338505148887634\n",
      "91 0.6334218978881836\n",
      "92 0.6329612731933594\n",
      "93 0.6325367093086243\n",
      "94 0.6322187781333923\n",
      "95 0.6318492889404297\n",
      "96 0.6313909888267517\n",
      "97 0.6308576464653015\n",
      "98 0.6302614212036133\n",
      "99 0.6297054886817932\n",
      "100 0.6291354298591614\n",
      "101 0.6286401152610779\n",
      "102 0.6281574964523315\n",
      "103 0.6274667382240295\n",
      "104 0.6267387866973877\n",
      "105 0.6261400580406189\n",
      "106 0.6256609559059143\n",
      "107 0.6250355839729309\n",
      "108 0.6243218779563904\n",
      "109 0.6237155199050903\n",
      "110 0.6231756210327148\n",
      "111 0.6224054098129272\n",
      "112 0.6216843724250793\n",
      "113 0.6210240721702576\n",
      "114 0.620354950428009\n",
      "115 0.6196464896202087\n",
      "116 0.6189256310462952\n",
      "117 0.6182121634483337\n",
      "118 0.6174910664558411\n",
      "119 0.6167362928390503\n",
      "120 0.6159422993659973\n",
      "121 0.6151277422904968\n",
      "122 0.6143164038658142\n",
      "123 0.6135221719741821\n",
      "124 0.6127364039421082\n",
      "125 0.6119291186332703\n",
      "126 0.6110921502113342\n",
      "127 0.610241711139679\n",
      "128 0.6093820929527283\n",
      "129 0.6085121035575867\n",
      "130 0.6076597571372986\n",
      "131 0.6068093180656433\n",
      "132 0.6059325933456421\n",
      "133 0.6050528883934021\n",
      "134 0.6041665077209473\n",
      "135 0.6032646298408508\n",
      "136 0.6023653149604797\n",
      "137 0.6014739274978638\n",
      "138 0.6005897521972656\n",
      "139 0.5996803641319275\n",
      "140 0.5987366437911987\n",
      "141 0.5978044867515564\n",
      "142 0.5968905091285706\n",
      "143 0.595950186252594\n",
      "144 0.5950257778167725\n",
      "145 0.5941001176834106\n",
      "146 0.5931492447853088\n",
      "147 0.5922171473503113\n",
      "148 0.5912831425666809\n",
      "149 0.5903419852256775\n",
      "150 0.5894134640693665\n",
      "151 0.5884745121002197\n",
      "152 0.587530791759491\n",
      "153 0.5865960717201233\n",
      "154 0.585663914680481\n",
      "155 0.5847355723381042\n",
      "156 0.5838072896003723\n",
      "157 0.5828753113746643\n",
      "158 0.5819520354270935\n",
      "159 0.5810402035713196\n",
      "160 0.5801281332969666\n",
      "161 0.5792088508605957\n",
      "162 0.5782813429832458\n",
      "163 0.5773536562919617\n",
      "164 0.5764520168304443\n",
      "165 0.5755983591079712\n",
      "166 0.5747582316398621\n",
      "167 0.5739172101020813\n",
      "168 0.5727993845939636\n",
      "169 0.5715819597244263\n",
      "170 0.5696359276771545\n",
      "171 0.5685388445854187\n",
      "172 0.5679963231086731\n",
      "173 0.5667639374732971\n",
      "174 0.5655736327171326\n",
      "175 0.5647850036621094\n",
      "176 0.5639070868492126\n",
      "177 0.5629053115844727\n",
      "178 0.5621320605278015\n",
      "179 0.5614345669746399\n",
      "180 0.5605925917625427\n",
      "181 0.5597063899040222\n",
      "182 0.5588958859443665\n",
      "183 0.5580300688743591\n",
      "184 0.5571293234825134\n",
      "185 0.5561203956604004\n",
      "186 0.5551772117614746\n",
      "187 0.5542783141136169\n",
      "188 0.5533235669136047\n",
      "189 0.5524516105651855\n",
      "190 0.5515146255493164\n",
      "191 0.5505827069282532\n",
      "192 0.5496594309806824\n",
      "193 0.5487895011901855\n",
      "194 0.5479022264480591\n",
      "195 0.5471118688583374\n",
      "196 0.5464173555374146\n",
      "197 0.5457732081413269\n",
      "198 0.5451920628547668\n",
      "199 0.5446397662162781\n",
      "200 0.5441601872444153\n",
      "201 0.543457567691803\n",
      "202 0.5428167581558228\n",
      "203 0.5423624515533447\n",
      "204 0.5418347716331482\n",
      "205 0.5412233471870422\n",
      "206 0.540698230266571\n",
      "207 0.5401888489723206\n",
      "208 0.539623498916626\n",
      "209 0.5390580892562866\n",
      "210 0.5385647416114807\n",
      "211 0.5380678772926331\n",
      "212 0.5375162959098816\n",
      "213 0.5370048880577087\n",
      "214 0.5365451574325562\n",
      "215 0.5360400676727295\n",
      "216 0.5355221033096313\n",
      "217 0.5350803732872009\n",
      "218 0.5346200466156006\n",
      "219 0.5341269373893738\n",
      "220 0.5336947441101074\n",
      "221 0.5332468748092651\n",
      "222 0.5327977538108826\n",
      "223 0.532373309135437\n",
      "224 0.5319532752037048\n",
      "225 0.5315754413604736\n",
      "226 0.5312022566795349\n",
      "227 0.5308284759521484\n",
      "228 0.5304893851280212\n",
      "229 0.5301510095596313\n",
      "230 0.5298080444335938\n",
      "231 0.5294843912124634\n",
      "232 0.5291555523872375\n",
      "233 0.528835117816925\n",
      "234 0.5285261273384094\n",
      "235 0.5282105207443237\n",
      "236 0.5278889536857605\n",
      "237 0.5275570750236511\n",
      "238 0.5272021889686584\n",
      "239 0.5268157124519348\n",
      "240 0.5263664126396179\n",
      "241 0.5258677005767822\n",
      "242 0.5253998041152954\n",
      "243 0.52498859167099\n",
      "244 0.5246230363845825\n",
      "245 0.5242605805397034\n",
      "246 0.5238611698150635\n",
      "247 0.5234255194664001\n",
      "248 0.5229325890541077\n",
      "249 0.522396445274353\n",
      "250 0.5218514800071716\n",
      "251 0.521389365196228\n",
      "252 0.5210375189781189\n",
      "253 0.5207781791687012\n",
      "254 0.5205793976783752\n",
      "255 0.5204069018363953\n",
      "256 0.5202460289001465\n",
      "257 0.5199242234230042\n",
      "258 0.5195667147636414\n",
      "259 0.5192821621894836\n",
      "260 0.5190882682800293\n",
      "261 0.5188854336738586\n",
      "262 0.5185713768005371\n",
      "263 0.5182436108589172\n",
      "264 0.5179809331893921\n",
      "265 0.5177633166313171\n",
      "266 0.517519474029541\n",
      "267 0.5172311663627625\n",
      "268 0.5169563889503479\n",
      "269 0.5167418122291565\n",
      "270 0.5165441036224365\n",
      "271 0.5163100957870483\n",
      "272 0.5160569548606873\n",
      "273 0.5158292651176453\n",
      "274 0.5156225562095642\n",
      "275 0.5154128074645996\n",
      "276 0.5151885151863098\n",
      "277 0.5149458050727844\n",
      "278 0.5147064328193665\n",
      "279 0.5144874453544617\n",
      "280 0.5142815113067627\n",
      "281 0.514074981212616\n",
      "282 0.5138667821884155\n",
      "283 0.5136660933494568\n",
      "284 0.5134764313697815\n",
      "285 0.5133000612258911\n",
      "286 0.5131346583366394\n",
      "287 0.5129714608192444\n",
      "288 0.5128046870231628\n",
      "289 0.5126341581344604\n",
      "290 0.5124626755714417\n",
      "291 0.512290894985199\n",
      "292 0.5121216177940369\n",
      "293 0.5119574069976807\n",
      "294 0.5117978453636169\n",
      "295 0.5116414427757263\n",
      "296 0.5114879608154297\n",
      "297 0.5113373398780823\n",
      "298 0.5111883282661438\n",
      "299 0.5110401511192322\n",
      "300 0.5108926892280579\n",
      "301 0.5107463002204895\n",
      "302 0.5105989575386047\n",
      "303 0.5104494690895081\n",
      "304 0.5102943778038025\n",
      "305 0.5101282596588135\n",
      "306 0.509947657585144\n",
      "307 0.5097512006759644\n",
      "308 0.5095493197441101\n",
      "309 0.5093528628349304\n",
      "310 0.5091702342033386\n",
      "311 0.5090034008026123\n",
      "312 0.5088502168655396\n",
      "313 0.5087071061134338\n",
      "314 0.5085697770118713\n",
      "315 0.5084357857704163\n",
      "316 0.508300244808197\n",
      "317 0.5081637501716614\n",
      "318 0.5080223679542542\n",
      "319 0.5078800320625305\n",
      "320 0.5077354311943054\n",
      "321 0.5075918436050415\n",
      "322 0.5074486136436462\n",
      "323 0.5073052644729614\n",
      "324 0.5071609616279602\n",
      "325 0.5070156455039978\n",
      "326 0.506870448589325\n",
      "327 0.5067271590232849\n",
      "328 0.5065895318984985\n",
      "329 0.5064626336097717\n",
      "330 0.5063598155975342\n",
      "331 0.5062961578369141\n",
      "332 0.5062995553016663\n",
      "333 0.5062862634658813\n",
      "334 0.5061495304107666\n",
      "335 0.5057581067085266\n",
      "336 0.5054503083229065\n",
      "337 0.5053803324699402\n",
      "338 0.5053995251655579\n",
      "339 0.5052793025970459\n",
      "340 0.5049789547920227\n",
      "341 0.5047988295555115\n",
      "342 0.5047814846038818\n",
      "343 0.5047300457954407\n",
      "344 0.5045537352561951\n",
      "345 0.504340648651123\n",
      "346 0.5042200684547424\n",
      "347 0.5042122602462769\n",
      "348 0.5041046738624573\n",
      "349 0.5038972496986389\n",
      "350 0.503756582736969\n",
      "351 0.503689169883728\n",
      "352 0.503594696521759\n",
      "353 0.5034382939338684\n",
      "354 0.5032891631126404\n",
      "355 0.5031319856643677\n",
      "356 0.5030612945556641\n",
      "357 0.5029451847076416\n",
      "358 0.5028237104415894\n",
      "359 0.5026556849479675\n",
      "360 0.5025418996810913\n",
      "361 0.502418041229248\n",
      "362 0.502332866191864\n",
      "363 0.5021764636039734\n",
      "364 0.5020583868026733\n",
      "365 0.5019000768661499\n",
      "366 0.5017955899238586\n",
      "367 0.5016408562660217\n",
      "368 0.5015375018119812\n",
      "369 0.5013730525970459\n",
      "370 0.5012515187263489\n",
      "371 0.5010725855827332\n",
      "372 0.5009422898292542\n",
      "373 0.5007711052894592\n",
      "374 0.5006337761878967\n",
      "375 0.5004683136940002\n",
      "376 0.5003090500831604\n",
      "377 0.5001416802406311\n",
      "378 0.49995312094688416\n",
      "379 0.4997718334197998\n",
      "380 0.4995603859424591\n",
      "381 0.49935469031333923\n",
      "382 0.49912428855895996\n",
      "383 0.49888214468955994\n",
      "384 0.4986342489719391\n",
      "385 0.4983525574207306\n",
      "386 0.4980801045894623\n",
      "387 0.497767835855484\n",
      "388 0.497457355260849\n",
      "389 0.4971179962158203\n",
      "390 0.49677470326423645\n",
      "391 0.4964420795440674\n",
      "392 0.4961259365081787\n",
      "393 0.4958333671092987\n",
      "394 0.49556753039360046\n",
      "395 0.4953141212463379\n",
      "396 0.49507936835289\n",
      "397 0.4948652684688568\n",
      "398 0.4946765899658203\n",
      "399 0.4945484697818756\n",
      "400 0.4944806396961212\n",
      "401 0.4944886267185211\n",
      "402 0.4942716658115387\n",
      "403 0.4938408434391022\n",
      "404 0.49334654211997986\n",
      "405 0.49315619468688965\n",
      "406 0.4931713342666626\n",
      "407 0.4930154085159302\n",
      "408 0.4926396310329437\n",
      "409 0.4922935664653778\n",
      "410 0.49218448996543884\n",
      "411 0.49209830164909363\n",
      "412 0.491790771484375\n",
      "413 0.4914415180683136\n",
      "414 0.49123620986938477\n",
      "415 0.4910876750946045\n",
      "416 0.49084022641181946\n",
      "417 0.49047747254371643\n",
      "418 0.490185022354126\n",
      "419 0.48997271060943604\n",
      "420 0.48969337344169617\n",
      "421 0.48932263255119324\n",
      "422 0.488923579454422\n",
      "423 0.48856648802757263\n",
      "424 0.48821818828582764\n",
      "425 0.48781052231788635\n",
      "426 0.48734864592552185\n",
      "427 0.48675957322120667\n",
      "428 0.4860413372516632\n",
      "429 0.48525238037109375\n",
      "430 0.48447108268737793\n",
      "431 0.4836339056491852\n",
      "432 0.48282361030578613\n",
      "433 0.4822982847690582\n",
      "434 0.48331117630004883\n",
      "435 0.47941145300865173\n",
      "436 0.4815309941768646\n",
      "437 0.48057830333709717\n",
      "438 0.4803064167499542\n",
      "439 0.4780679941177368\n",
      "440 0.47952958941459656\n",
      "441 0.47731804847717285\n",
      "442 0.47859010100364685\n",
      "443 0.4768047332763672\n",
      "444 0.47707244753837585\n",
      "445 0.47584834694862366\n",
      "446 0.47654077410697937\n",
      "447 0.47497713565826416\n",
      "448 0.4757535755634308\n",
      "449 0.4743112027645111\n",
      "450 0.4743954837322235\n",
      "451 0.473560094833374\n",
      "452 0.47387468814849854\n",
      "453 0.472644567489624\n",
      "454 0.472910076379776\n",
      "455 0.47205570340156555\n",
      "456 0.4721204340457916\n",
      "457 0.4714343547821045\n",
      "458 0.47141194343566895\n",
      "459 0.4708229601383209\n",
      "460 0.4706357419490814\n",
      "461 0.4703506529331207\n",
      "462 0.470121294260025\n",
      "463 0.4697782099246979\n",
      "464 0.46944376826286316\n",
      "465 0.469287246465683\n",
      "466 0.4689234495162964\n",
      "467 0.46877095103263855\n",
      "468 0.4683573544025421\n",
      "469 0.4681767523288727\n",
      "470 0.46791303157806396\n",
      "471 0.4676573574542999\n",
      "472 0.46746739745140076\n",
      "473 0.46712684631347656\n",
      "474 0.466964989900589\n",
      "475 0.46668192744255066\n",
      "476 0.46646830439567566\n",
      "477 0.46626782417297363\n",
      "478 0.46600738167762756\n",
      "479 0.4658515751361847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 0.46563613414764404\n",
      "481 0.4654579162597656\n",
      "482 0.4653378427028656\n",
      "483 0.46524420380592346\n",
      "484 0.4653913080692291\n",
      "485 0.46588239073753357\n",
      "486 0.46699056029319763\n",
      "487 0.467331200838089\n",
      "488 0.4662487804889679\n",
      "489 0.4641333520412445\n",
      "490 0.4642820656299591\n",
      "491 0.4656153619289398\n",
      "492 0.46477851271629333\n",
      "493 0.4633304178714752\n",
      "494 0.46369805932044983\n",
      "495 0.4642646312713623\n",
      "496 0.4634857177734375\n",
      "497 0.4626745879650116\n",
      "498 0.4632602035999298\n",
      "499 0.46333077549934387\n",
      "500 0.4624011516571045\n",
      "501 0.4622972905635834\n",
      "502 0.4627484083175659\n",
      "503 0.46223214268684387\n",
      "504 0.461690217256546\n",
      "505 0.4618891179561615\n",
      "506 0.46190550923347473\n",
      "507 0.46142634749412537\n",
      "508 0.4611726701259613\n",
      "509 0.4613400399684906\n",
      "510 0.46121451258659363\n",
      "511 0.46080517768859863\n",
      "512 0.46067318320274353\n",
      "513 0.46076181530952454\n",
      "514 0.4605822265148163\n",
      "515 0.46026208996772766\n",
      "516 0.460141658782959\n",
      "517 0.4601488411426544\n",
      "518 0.46003472805023193\n",
      "519 0.45976710319519043\n",
      "520 0.4596099853515625\n",
      "521 0.45957016944885254\n",
      "522 0.45949503779411316\n",
      "523 0.4593086242675781\n",
      "524 0.4591117799282074\n",
      "525 0.45900094509124756\n",
      "526 0.4589344561100006\n",
      "527 0.45883771777153015\n",
      "528 0.4586775004863739\n",
      "529 0.4585106670856476\n",
      "530 0.4583752453327179\n",
      "531 0.4582822620868683\n",
      "532 0.45819398760795593\n",
      "533 0.45808425545692444\n",
      "534 0.4579487144947052\n",
      "535 0.4578014314174652\n",
      "536 0.457661896944046\n",
      "537 0.4575357735157013\n",
      "538 0.45742377638816833\n",
      "539 0.45732030272483826\n",
      "540 0.45721936225891113\n",
      "541 0.45711901783943176\n",
      "542 0.4570213258266449\n",
      "543 0.45692452788352966\n",
      "544 0.4568411409854889\n",
      "545 0.45676878094673157\n",
      "546 0.4567365348339081\n",
      "547 0.45673704147338867\n",
      "548 0.45684027671813965\n",
      "549 0.45699062943458557\n",
      "550 0.4572998285293579\n",
      "551 0.4573819935321808\n",
      "552 0.4573366641998291\n",
      "553 0.4566444158554077\n",
      "554 0.45591530203819275\n",
      "555 0.45546603202819824\n",
      "556 0.4554884135723114\n",
      "557 0.45578184723854065\n",
      "558 0.4559516906738281\n",
      "559 0.45587465167045593\n",
      "560 0.4553994834423065\n",
      "561 0.45493945479393005\n",
      "562 0.4547061026096344\n",
      "563 0.4547383785247803\n",
      "564 0.4548795521259308\n",
      "565 0.4549029767513275\n",
      "566 0.45477500557899475\n",
      "567 0.4544597566127777\n",
      "568 0.4541551172733307\n",
      "569 0.45395350456237793\n",
      "570 0.45388221740722656\n",
      "571 0.4538862705230713\n",
      "572 0.45388302206993103\n",
      "573 0.45384156703948975\n",
      "574 0.45370128750801086\n",
      "575 0.4535757005214691\n",
      "576 0.45339810848236084\n",
      "577 0.45320987701416016\n",
      "578 0.4530111253261566\n",
      "579 0.45283910632133484\n",
      "580 0.4526820182800293\n",
      "581 0.4525410830974579\n",
      "582 0.4524099826812744\n",
      "583 0.45228567719459534\n",
      "584 0.4521714150905609\n",
      "585 0.45207011699676514\n",
      "586 0.45199182629585266\n",
      "587 0.45194825530052185\n",
      "588 0.45199504494667053\n",
      "589 0.45221757888793945\n",
      "590 0.4528675079345703\n",
      "591 0.45385730266571045\n",
      "592 0.455318421125412\n",
      "593 0.4546123743057251\n",
      "594 0.4527272880077362\n",
      "595 0.4509645700454712\n",
      "596 0.45145341753959656\n",
      "597 0.45290419459342957\n",
      "598 0.45252132415771484\n",
      "599 0.4510596692562103\n",
      "600 0.4503772556781769\n",
      "601 0.45113399624824524\n",
      "602 0.4517918527126312\n",
      "603 0.4509400427341461\n",
      "604 0.45000147819519043\n",
      "605 0.45011892914772034\n",
      "606 0.4506435692310333\n",
      "607 0.4505032002925873\n",
      "608 0.44972744584083557\n",
      "609 0.4495009183883667\n",
      "610 0.44985488057136536\n",
      "611 0.44989168643951416\n",
      "612 0.44945093989372253\n",
      "613 0.44904860854148865\n",
      "614 0.4491061866283417\n",
      "615 0.4492915868759155\n",
      "616 0.44914495944976807\n",
      "617 0.4487808048725128\n",
      "618 0.4485205113887787\n",
      "619 0.44850024580955505\n",
      "620 0.4486166536808014\n",
      "621 0.44879984855651855\n",
      "622 0.44884636998176575\n",
      "623 0.4487525522708893\n",
      "624 0.44840049743652344\n",
      "625 0.4479213058948517\n",
      "626 0.4475678503513336\n",
      "627 0.44745108485221863\n",
      "628 0.4475705623626709\n",
      "629 0.4481104612350464\n",
      "630 0.44978418946266174\n",
      "631 0.4515415132045746\n",
      "632 0.45017969608306885\n",
      "633 0.4475747048854828\n",
      "634 0.4469377100467682\n",
      "635 0.44839462637901306\n",
      "636 0.4494164288043976\n",
      "637 0.4486638605594635\n",
      "638 0.44660115242004395\n",
      "639 0.4458198845386505\n",
      "640 0.44673988223075867\n",
      "641 0.44811150431632996\n",
      "642 0.4493112862110138\n",
      "643 0.44774436950683594\n",
      "644 0.44539758563041687\n",
      "645 0.4451563358306885\n",
      "646 0.44745030999183655\n",
      "647 0.4517107307910919\n",
      "648 0.45071911811828613\n",
      "649 0.4459266662597656\n",
      "650 0.44496798515319824\n",
      "651 0.447929710149765\n",
      "652 0.44641947746276855\n",
      "653 0.4433889389038086\n",
      "654 0.44441795349121094\n",
      "655 0.448713093996048\n",
      "656 0.44826018810272217\n",
      "657 0.44545337557792664\n",
      "658 0.4424471855163574\n",
      "659 0.44494399428367615\n",
      "660 0.4471181333065033\n",
      "661 0.443751722574234\n",
      "662 0.44117438793182373\n",
      "663 0.44013312458992004\n",
      "664 0.4410935640335083\n",
      "665 0.4444183111190796\n",
      "666 0.4483835697174072\n",
      "667 0.4572630822658539\n",
      "668 0.4447719156742096\n",
      "669 0.44199374318122864\n",
      "670 0.4495837986469269\n",
      "671 0.441101998090744\n",
      "672 0.44061437249183655\n",
      "673 0.4475128948688507\n",
      "674 0.44178012013435364\n",
      "675 0.43841373920440674\n",
      "676 0.4415501654148102\n",
      "677 0.440364807844162\n",
      "678 0.43782660365104675\n",
      "679 0.43910086154937744\n",
      "680 0.4395042359828949\n",
      "681 0.4375803470611572\n",
      "682 0.4367845058441162\n",
      "683 0.43814751505851746\n",
      "684 0.43990087509155273\n",
      "685 0.4386915862560272\n",
      "686 0.43689775466918945\n",
      "687 0.4358954429626465\n",
      "688 0.4366621971130371\n",
      "689 0.4376470148563385\n",
      "690 0.4367959201335907\n",
      "691 0.4356009066104889\n",
      "692 0.4350018799304962\n",
      "693 0.4353528916835785\n",
      "694 0.43604397773742676\n",
      "695 0.4361058473587036\n",
      "696 0.43591606616973877\n",
      "697 0.4350496828556061\n",
      "698 0.43434834480285645\n",
      "699 0.43396297097206116\n",
      "700 0.43395718932151794\n",
      "701 0.4342002868652344\n",
      "702 0.4344621002674103\n",
      "703 0.4350602328777313\n",
      "704 0.4355737864971161\n",
      "705 0.43711456656455994\n",
      "706 0.43753036856651306\n",
      "707 0.4382077753543854\n",
      "708 0.4352548122406006\n",
      "709 0.43294987082481384\n",
      "710 0.43279385566711426\n",
      "711 0.4344116151332855\n",
      "712 0.43675848841667175\n",
      "713 0.4367823898792267\n",
      "714 0.4365338087081909\n",
      "715 0.4336753189563751\n",
      "716 0.4317350685596466\n",
      "717 0.4317384660243988\n",
      "718 0.43321123719215393\n",
      "719 0.4353632628917694\n",
      "720 0.43577292561531067\n",
      "721 0.43605414032936096\n",
      "722 0.4334418773651123\n",
      "723 0.4312096834182739\n",
      "724 0.4305379390716553\n",
      "725 0.4317108690738678\n",
      "726 0.4340460002422333\n",
      "727 0.435587078332901\n",
      "728 0.4373476803302765\n",
      "729 0.434423565864563\n",
      "730 0.4310894310474396\n",
      "731 0.42993831634521484\n",
      "732 0.431791216135025\n",
      "733 0.433687299489975\n",
      "734 0.432348370552063\n",
      "735 0.4303736388683319\n",
      "736 0.42901337146759033\n",
      "737 0.42924317717552185\n",
      "738 0.43053725361824036\n",
      "739 0.4317656457424164\n",
      "740 0.43325796723365784\n",
      "741 0.4328213632106781\n",
      "742 0.4322997033596039\n",
      "743 0.43020346760749817\n",
      "744 0.428625226020813\n",
      "745 0.4278728663921356\n",
      "746 0.4280940592288971\n",
      "747 0.42907050251960754\n",
      "748 0.4305143654346466\n",
      "749 0.43358373641967773\n",
      "750 0.4366028606891632\n",
      "751 0.44185662269592285\n",
      "752 0.437725692987442\n",
      "753 0.43149587512016296\n",
      "754 0.42681291699409485\n",
      "755 0.4297012388706207\n",
      "756 0.4349580705165863\n",
      "757 0.43233057856559753\n",
      "758 0.4276919364929199\n",
      "759 0.42630088329315186\n",
      "760 0.4290860593318939\n",
      "761 0.43209078907966614\n",
      "762 0.4306061565876007\n",
      "763 0.4280034005641937\n",
      "764 0.42562493681907654\n",
      "765 0.4246072769165039\n",
      "766 0.42468154430389404\n",
      "767 0.42579925060272217\n",
      "768 0.4293404519557953\n",
      "769 0.4380563199520111\n",
      "770 0.4483746588230133\n",
      "771 0.43735480308532715\n",
      "772 0.4257570505142212\n",
      "773 0.43147143721580505\n",
      "774 0.43315207958221436\n",
      "775 0.4259304106235504\n",
      "776 0.4279996156692505\n",
      "777 0.430649071931839\n",
      "778 0.4261690080165863\n",
      "779 0.42558398842811584\n",
      "780 0.4290691316127777\n",
      "781 0.42790675163269043\n",
      "782 0.42398515343666077\n",
      "783 0.4245847761631012\n",
      "784 0.42757177352905273\n",
      "785 0.42766785621643066\n",
      "786 0.4251112639904022\n",
      "787 0.4232226312160492\n",
      "788 0.4240645468235016\n",
      "789 0.42605528235435486\n",
      "790 0.42650333046913147\n",
      "791 0.42501088976860046\n",
      "792 0.42306843400001526\n",
      "793 0.42256441712379456\n",
      "794 0.4234779179096222\n",
      "795 0.4241809546947479\n",
      "796 0.4236510097980499\n",
      "797 0.42261043190956116\n",
      "798 0.4224635064601898\n",
      "799 0.42306390404701233\n",
      "800 0.4231949746608734\n",
      "801 0.4225955009460449\n",
      "802 0.4220496118068695\n",
      "803 0.4221384823322296\n",
      "804 0.4225407540798187\n",
      "805 0.4226848781108856\n",
      "806 0.4224463701248169\n",
      "807 0.4220314025878906\n",
      "808 0.4217539131641388\n",
      "809 0.4217371940612793\n",
      "810 0.42187580466270447\n",
      "811 0.4219653904438019\n",
      "812 0.42187413573265076\n",
      "813 0.42166033387184143\n",
      "814 0.42146381735801697\n",
      "815 0.4213903248310089\n",
      "816 0.4214281141757965\n",
      "817 0.42148685455322266\n",
      "818 0.4214823246002197\n",
      "819 0.4213881492614746\n",
      "820 0.4212513864040375\n",
      "821 0.42113280296325684\n",
      "822 0.4210691750049591\n",
      "823 0.4210576117038727\n",
      "824 0.42107120156288147\n",
      "825 0.42108210921287537\n",
      "826 0.42107096314430237\n",
      "827 0.4210340082645416\n",
      "828 0.4209732115268707\n",
      "829 0.42089948058128357\n",
      "830 0.42082035541534424\n",
      "831 0.42074546217918396\n",
      "832 0.42068031430244446\n",
      "833 0.42062780261039734\n",
      "834 0.4205869734287262\n",
      "835 0.4205549657344818\n",
      "836 0.4205286204814911\n",
      "837 0.420505553483963\n",
      "838 0.42048534750938416\n",
      "839 0.4204684793949127\n",
      "840 0.420457124710083\n",
      "841 0.4204535186290741\n",
      "842 0.4204629957675934\n",
      "843 0.42049190402030945\n",
      "844 0.4205568730831146\n",
      "845 0.4206753969192505\n",
      "846 0.4208885729312897\n",
      "847 0.4212273061275482\n",
      "848 0.421762079000473\n",
      "849 0.4224485456943512\n",
      "850 0.4232740104198456\n",
      "851 0.42377546429634094\n",
      "852 0.4238015115261078\n",
      "853 0.4228343069553375\n",
      "854 0.42151275277137756\n",
      "855 0.4203318655490875\n",
      "856 0.4198441803455353\n",
      "857 0.42006370425224304\n",
      "858 0.4207594096660614\n",
      "859 0.4217201769351959\n",
      "860 0.42268049716949463\n",
      "861 0.4234062731266022\n",
      "862 0.4232393801212311\n",
      "863 0.4222402274608612\n",
      "864 0.42071017622947693\n",
      "865 0.4197019040584564\n",
      "866 0.4196368157863617\n",
      "867 0.4203348159790039\n",
      "868 0.4213775396347046\n",
      "869 0.42229270935058594\n",
      "870 0.42273759841918945\n",
      "871 0.42226719856262207\n",
      "872 0.42111432552337646\n",
      "873 0.41984882950782776\n",
      "874 0.4193359315395355\n",
      "875 0.4197033643722534\n",
      "876 0.4204306900501251\n",
      "877 0.42097124457359314\n",
      "878 0.4209870398044586\n",
      "879 0.420560747385025\n",
      "880 0.419888973236084\n",
      "881 0.41930505633354187\n",
      "882 0.419025182723999\n",
      "883 0.41908180713653564\n",
      "884 0.4193285405635834\n",
      "885 0.41956159472465515\n",
      "886 0.4196588695049286\n",
      "887 0.4195760190486908\n",
      "888 0.419371098279953\n",
      "889 0.41911712288856506\n",
      "890 0.41889914870262146\n",
      "891 0.41876220703125\n",
      "892 0.4187135398387909\n",
      "893 0.418732613325119\n",
      "894 0.41878581047058105\n",
      "895 0.41883817315101624\n",
      "896 0.4188612699508667\n",
      "897 0.41884830594062805\n",
      "898 0.41880330443382263\n",
      "899 0.4187403917312622\n",
      "900 0.4186667501926422\n",
      "901 0.4185910224914551\n",
      "902 0.41851818561553955\n",
      "903 0.41845205426216125\n",
      "904 0.4183926582336426\n",
      "905 0.4183407127857208\n",
      "906 0.4182964563369751\n",
      "907 0.41825902462005615\n",
      "908 0.4182261526584625\n",
      "909 0.4181959927082062\n",
      "910 0.41816815733909607\n",
      "911 0.4181425869464874\n",
      "912 0.41811931133270264\n",
      "913 0.41809892654418945\n",
      "914 0.41808292269706726\n",
      "915 0.4180738031864166\n",
      "916 0.41807636618614197\n",
      "917 0.4180983304977417\n",
      "918 0.4181543290615082\n",
      "919 0.41826701164245605\n",
      "920 0.4184763431549072\n",
      "921 0.4188394248485565\n",
      "922 0.4194442927837372\n",
      "923 0.42035147547721863\n",
      "924 0.4215782880783081\n",
      "925 0.4227490723133087\n",
      "926 0.42336535453796387\n",
      "927 0.4224752187728882\n",
      "928 0.4205656349658966\n",
      "929 0.4185408353805542\n",
      "930 0.417655348777771\n",
      "931 0.4180946350097656\n",
      "932 0.41931796073913574\n",
      "933 0.4206482470035553\n",
      "934 0.4213905334472656\n",
      "935 0.4211678206920624\n",
      "936 0.4198954105377197\n",
      "937 0.418383926153183\n",
      "938 0.4174862205982208\n",
      "939 0.41759562492370605\n",
      "940 0.4183832108974457\n",
      "941 0.419238418340683\n",
      "942 0.41974207758903503\n",
      "943 0.41966512799263\n",
      "944 0.41904354095458984\n",
      "945 0.41814133524894714\n",
      "946 0.4174005091190338\n",
      "947 0.4171338379383087\n",
      "948 0.41734084486961365\n",
      "949 0.41774919629096985\n",
      "950 0.4180397093296051\n",
      "951 0.4180572032928467\n",
      "952 0.41780614852905273\n",
      "953 0.4174262285232544\n",
      "954 0.41708365082740784\n",
      "955 0.41689956188201904\n",
      "956 0.4168960154056549\n",
      "957 0.4170100688934326\n",
      "958 0.4171489477157593\n",
      "959 0.417236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 0.41723620891571045\n",
      "961 0.4171471893787384\n",
      "962 0.41700300574302673\n",
      "963 0.41684797406196594\n",
      "964 0.41671815514564514\n",
      "965 0.4166286885738373\n",
      "966 0.41658034920692444\n",
      "967 0.4165671765804291\n",
      "968 0.4165777266025543\n",
      "969 0.416596919298172\n",
      "970 0.41661229729652405\n",
      "971 0.4166182279586792\n",
      "972 0.4166136085987091\n",
      "973 0.416599303483963\n",
      "974 0.41657671332359314\n",
      "975 0.41654887795448303\n",
      "976 0.41651809215545654\n",
      "977 0.4164859354496002\n",
      "978 0.41645336151123047\n",
      "979 0.416422963142395\n",
      "980 0.4163973033428192\n",
      "981 0.4163788855075836\n",
      "982 0.41636982560157776\n",
      "983 0.41637349128723145\n",
      "984 0.4163939952850342\n",
      "985 0.4164365530014038\n",
      "986 0.41650819778442383\n",
      "987 0.41661903262138367\n",
      "988 0.4167815148830414\n",
      "989 0.4170093536376953\n",
      "990 0.4173101484775543\n",
      "991 0.4176810681819916\n",
      "992 0.4180784225463867\n",
      "993 0.418428897857666\n",
      "994 0.4185844361782074\n",
      "995 0.4184536635875702\n",
      "996 0.4179619252681732\n",
      "997 0.41725805401802063\n",
      "998 0.41652336716651917\n",
      "999 0.41597220301628113\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# prepare dataset\n",
    "xy = np.loadtxt('diabetes_for_numpy.csv', delimiter=',', dtype=np.float32)\n",
    "#原数据有字段名，适合pandas读取，numpy只需要读取数据，不需要表头（字段名）\n",
    "x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵\n",
    "z_data = torch.from_numpy(xy[:, -1])# 不是二维矩阵，是一位标量\n",
    "# design model using class\n",
    " \n",
    " \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6) # 输入数据x的特征是8维，x有8个特征\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid() # 将其看作是网络的一层，而不是简单的函数使用\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x)) # y hat\n",
    "        return x\n",
    " \n",
    " \n",
    "model = Model()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.BCELoss(size_average = True)\n",
    "criterion = torch.nn.BCELoss(reduction='mean')  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    " \n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "# training cycle forward, backward, update\n",
    "for epoch in range(1000):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    " \n",
    "    optimizer.step()\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ad25d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "770e7caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 8]), torch.Size([768, 1]), torch.Size([768]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape,y_data.shape,z_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ed49b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "093a6853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6ff8723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6.0000, 148.0000,  72.0000,  ...,  33.6000,   0.6270,  50.0000],\n",
       "        [  1.0000,  85.0000,  66.0000,  ...,  26.6000,   0.3510,  31.0000],\n",
       "        [  8.0000, 183.0000,  64.0000,  ...,  23.3000,   0.6720,  32.0000],\n",
       "        ...,\n",
       "        [  5.0000, 121.0000,  72.0000,  ...,  26.2000,   0.2450,  30.0000],\n",
       "        [  1.0000, 126.0000,  60.0000,  ...,  30.1000,   0.3490,  47.0000],\n",
       "        [  1.0000,  93.0000,  70.0000,  ...,  30.4000,   0.3150,  23.0000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75d12a",
   "metadata": {},
   "source": [
    "代码说明 ：   \n",
    "1、diabetes.csv数据集老师给了下载地址，该数据集需和源代码放在同一个文件夹内。  https://www.kaggle.com/datasets/saurabh00007/diabetescsv?select=diabetes.csv \n",
    "\n",
    "2、如果想查看某些层的参数，以神经网络的第一层参数为例，可按照以下方法进行。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42016a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1_weight tensor([[-0.4514, -0.4887,  1.0424,  0.2571, -0.0209,  0.1901,  4.5028,  0.5105],\n",
      "        [-0.7263,  0.1537,  0.9801, -0.6841, -0.6769,  1.0209,  0.0786, -0.5155],\n",
      "        [ 0.1706, -0.0342,  0.1077, -0.1231,  0.0071,  0.0661, -3.0422, -0.2842],\n",
      "        [ 0.4715,  0.0412, -0.0266, -0.0395,  0.0092,  0.1083, -0.8113, -0.1525],\n",
      "        [ 1.3948, -0.1454, -0.3775, -0.7626, -0.0341, -0.6389, -1.5411,  0.9462],\n",
      "        [-0.1139,  0.0055,  0.0397, -0.0281, -0.0138,  0.0724,  1.0393,  0.0481]])\n",
      "layer1_weight.shape torch.Size([6, 8])\n",
      "layer1_bias tensor([ 1.4834,  2.3738,  4.9478, -3.8952,  5.4795, -5.1607])\n",
      "layer1_bias.shape torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# 参数说明\n",
    "# 第一层的参数：\n",
    "layer1_weight = model.linear1.weight.data\n",
    "layer1_bias = model.linear1.bias.data\n",
    "print(\"layer1_weight\", layer1_weight)\n",
    "print(\"layer1_weight.shape\", layer1_weight.shape)\n",
    "print(\"layer1_bias\", layer1_bias)\n",
    "print(\"layer1_bias.shape\", layer1_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e25eda",
   "metadata": {},
   "source": [
    "3、更改epoch，以准确率acc为评价指标，源代码和结果如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3eabd106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1743.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data.shape torch.Size([768, 8])\n",
      "loss =  0.6470955014228821 acc =  0.6510416666666666\n",
      "loss =  0.647078812122345 acc =  0.6510416666666666\n",
      "loss =  0.6470630168914795 acc =  0.6510416666666666\n",
      "loss =  0.6470480561256409 acc =  0.6510416666666666\n",
      "loss =  0.6470339298248291 acc =  0.6510416666666666\n",
      "loss =  0.6470206379890442 acc =  0.6510416666666666\n",
      "loss =  0.6470082402229309 acc =  0.6510416666666666\n",
      "loss =  0.6469965577125549 acc =  0.6510416666666666\n",
      "loss =  0.6469854712486267 acc =  0.6510416666666666\n",
      "loss =  0.646975040435791 acc =  0.6510416666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    " \n",
    "# prepare dataset\n",
    "xy = np.loadtxt('diabetes_for_numpy.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要\n",
    "print(\"input data.shape\", x_data.shape)\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵\n",
    " \n",
    "# print(x_data.shape)\n",
    "# design model using class\n",
    " \n",
    " \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 2)\n",
    "        self.linear4 = torch.nn.Linear(2, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x)) \n",
    "        x = self.sigmoid(self.linear4(x))  # y hat\n",
    "        return x\n",
    " \n",
    " \n",
    "model = Model()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.BCELoss(size_average = True)\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    " \n",
    " \n",
    "# training cycle forward, backward, update\n",
    "for epoch in tqdm(range(100)):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # print(epoch, loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if epoch%10 == 9:\n",
    "        y_pred_label = torch.where(y_pred>=0.5,torch.tensor([1.0]),torch.tensor([0.0]))\n",
    " \n",
    "        acc = torch.eq(y_pred_label, y_data).sum().item()/y_data.size(0)\n",
    "        print(\"loss = \",loss.item(), \"acc = \",acc)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "489176a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 277/1000000 [00:00<12:07, 1374.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data.shape torch.Size([768, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████                                                                | 100146/1000000 [01:23<12:37, 1187.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.39477792382240295 acc =  0.80859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▏                                                        | 200218/1000000 [02:48<11:15, 1183.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.3963114023208618 acc =  0.8033854166666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▎                                                 | 300128/1000000 [04:15<10:33, 1104.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.39250388741493225 acc =  0.8020833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████▍                                          | 400220/1000000 [05:43<08:34, 1166.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.385451078414917 acc =  0.8111979166666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████▌                                   | 500224/1000000 [07:11<07:29, 1110.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.3897014558315277 acc =  0.796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████▌                            | 600246/1000000 [08:39<05:47, 1150.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.40235015749931335 acc =  0.8072916666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████▋                     | 700166/1000000 [10:07<04:27, 1120.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.38106414675712585 acc =  0.8098958333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████▊              | 800185/1000000 [11:37<02:58, 1117.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.38053008913993835 acc =  0.8098958333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████▉       | 900124/1000000 [13:06<01:29, 1113.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.38725635409355164 acc =  0.8111979166666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1000000/1000000 [14:36<00:00, 1141.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.39199838042259216 acc =  0.80859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    " \n",
    "# prepare dataset\n",
    "xy = np.loadtxt('diabetes_for_numpy.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要\n",
    "print(\"input data.shape\", x_data.shape)\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵\n",
    " \n",
    "# print(x_data.shape)\n",
    "# design model using class\n",
    " \n",
    " \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 2)\n",
    "        self.linear4 = torch.nn.Linear(2, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x)) \n",
    "        x = self.sigmoid(self.linear4(x))  # y hat\n",
    "        return x\n",
    " \n",
    " \n",
    "model = Model()\n",
    " \n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.BCELoss(size_average = True)\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    " \n",
    " \n",
    "# training cycle forward, backward, update\n",
    "for epoch in tqdm(range(1000000)):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # print(epoch, loss.item())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if epoch%100000 == 99999:\n",
    "        y_pred_label = torch.where(y_pred>=0.5,torch.tensor([1.0]),torch.tensor([0.0]))\n",
    " \n",
    "        acc = torch.eq(y_pred_label, y_data).sum().item()/y_data.size(0)\n",
    "        print(\"loss = \",loss.item(), \"acc = \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ff632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
